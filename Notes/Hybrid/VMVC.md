# Basic info
- Title: Volumetric and Multi-View CNNs for Object Classification on 3D Data
- Author: Charles R. Qi, Hao Su, Matthias Nie√üner, Angela Dai, Mengyuan Yan & Leonidas J. Guibas
- Affiliation: Stanford University
- Publication status: 2016 CVPR
- Short name: VMVC
- Year: 2016

# Score
- Idea: 4
- Usability: 4
- Presentation: 5
- Overall: 4

# Contributions
## Problem addressed / Motivation
- While the extension of 2D CNN to 3D seems natural, the additional computational complexity (volumetric domain) and data sparity introduces significant challenges: for instance, in an image, every pixel contains observed information, whereas in 3D, a shape is only defined on its surface.

## Idea / Observation / Contribution
- Propose two volumetric CNN network architectures that signifcantly improve state-of-the-art of volumetric CNNs on 3D shape classification.
- Show how to reduce the gap between volumetric CNNs and multi-view CNNs.
- Introduce a new multi-resolution component to multi-view CNNs, which improves their already compelling performance.
- Introduce a dataset of real-world 3D data, constructed using dense 3D reconstruction.

<p align="center">
  <img src="http://graphics.stanford.edu/projects/3dcnn/teaser.jpg" width = 700>
</p>

## Formulation / Solver / Implementation
- First network introduces auxiliary learning tasks by classifying part of an object, which help to scrutize details of 3D objects more deeply. 
- This helps the problem with when the volumetric CNN overfits to the training data, it has no incentive to continue learning.
- Mlpconv used instead of conv layer and max pooling layer, as mlpconv has a three-layer structure and is thus a universal function approximator if enough neurons are provided in its intermediate layers.
- Therefore, mlpconv is a powerful filter for feature extraction of local patches, enchancing approximation of more abstract representations.
- Also, mlpconv has to be more discrimative with fewer parameters than ordinary convolution with pooling.
- Second network uses long anisotropic kernels to probe for long-distance interactions.
- The use of an elongated anisotropic kernel helps capture the global structure of the 3D volume.
- In contrast to traditional isotropic kernels, an anisotropic probing module has the advantage of aggregating long-range interactions in the early feature learning stage with fewer parameters.
- By combining data augmentation with a multi-orientation pooling, a significant performance improvement for both networks is observed.
- Different rotations generated by changing both azimuth and elevation angles.
- For multi-view method, introduced a multi-resolution 3D filter to capture information at multiple scales.
- *Sphere rendering* is performed at different volume resolutions. (Sphere used for discretization as they are view-invariant).
- This process helps to regularise potential noise or irregularities in real-world scanned data.

## Useful info / tips
- Performance gap between voxel and multi-view due to two factors:
  - Input resolution
  - Network architecture differences
- Their 3D multi-resolution filtering is different from classical 2D multi-resolution approaches, since the 3D filtering respects the distance in 3D.

# Evaluation
## Dataset
- ModelNet40
- Own dataset

## Metrics
- Voxel resolution 30x30x30.
- AlexNet used for multi-view method.
- For multi-view 20 views were used.

## Results

#### ModelNet40

| Network      | Class Accuracy | Instance Accuracy |
| ------------ | -------------- | ----------------- |
| SubvolumeSup | **86.0**       | 89.2              |
| AniProbing   | 85.6           | **89.9**          |
| Multi-View   | 86.6           | 89.5              |

# Resource
## Paper
https://arxiv.org/abs/1604.03265

## Project page
http://graphics.stanford.edu/projects/3dcnn/

## Source code
https://github.com/charlesq34/3dcnn.torch

## Paper connections
- Voxel
- Multi-view
- 3D CNN
- 2D CNN

## Software & Hardware
- Torch
