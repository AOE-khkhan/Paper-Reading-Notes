# Terminology
This document contains important information on many topics listed below, related to my PhD project on `Application of Deep Learning for the Decomposition of 3D Shape for Hexahedral Mesh Generation`.
- [Machine Learning](#machine-learning)
- [CAD/CAE](#computer-aided-design-and-computer-aided-engineering)
- [Programming](#programming)
- [Mathematics](#mathematics)

## Machine Learning
### Context-Free Grammars

A *context-free grammar (CFG)* is a set of recursive writing rules (or **productions**) used to generate patterns of strings.

A CFG consists of the following components:
- A set of **terminal symbols**, which are the characters of the alphabet that appear in the strings generated by the grammar.
- A set of **nonterminal symbols**, which are placeholders for patterns of terminal symbols that can be generated by the nonterminal symbols.
- A set of **productions**, which are rules for replacing (or rewriting) nonterminal symbols (on the left side of the production) in a string with other nonterminal or terminal symbols (on the right side of the production).
- A **start symbol**, which is a special nonterminal symbol that appears in the intial string generated by the grammar.

To generate a string of terminal symbols from a CFG, we:
- Begin with a string consisting of the start symbol.
- Apply one of the productions with the start symbol on the left hand size, replacing the start symbol with the right hand sidde of the production.
- Repeat the process of selecting nonterminal symbols in the string,and replacing them with the right hand side of some corresponding production, until all nonterminals have been replaced by terminal symbols.

#### Sources
- https://www.cs.rochester.edu/~nelson/courses/csc_173/grammars/cfg.html

## Computer Aided Design and Computer Aided Engineering
- [Geometric Idealisation](#geometric-idealisation)
- [Geometric Clean Up](#geometric-clean-up)
- [CAD/CAE Integration](#cad-&-cae-integration)

### Geometric Idealisation

### Geometric Clean Up

### CAD & CAE Integration

## Programming
- [Python](#python)
- [Pytorch](#pytorch)

### Python

<hr>

### Pytorch
Pytorch differs from Tensorflow and Caffe etc. due to the unique way it builds its neural networks. Other machine learning frameworks use a **static** method, where one has to build a neural network and reuse the same structure again and again. This is called **Define and Run**, which means that if you want to change how the network behaves you must start from scratch again.

Pytorch instead uses a technique called *reverse-mode auto differentiation*, which allows you to change the way your network behaves arbitrarily with zero lag or overhead. This means that it has a **dynamic** method of building its graph of the network, where the graph is built on the fly. This **Define by Run"** capability allows for more flexiblity and is why Pytorch is becoming more dominant in research applications.

<p align="center">
  <img src="https://cdn-images-1.medium.com/max/1600/1*5PLIVNA5fIqEC8-kZ260KQ.gif" width=400>
</p>

#### Tensor Functions
<details>
  <summary><code>torch.clamp(<i>input, min, max, out=None</i>) → Tensor</code><br/> <blockquote>Clamps all elements in <b>input</b> into the range <b>[min, max]</b> and returns a resulting tensor.<blockquote></summary>
  <pre>
  <code>
  >>> a = torch.randn(4)
  >>> a
  <b>tensor([-1.7120,  0.1734, -0.0478, -0.0922])</b>
  >>> torch.clamp(a, min=-0.5, max=0.5)
  <b>tensor([-0.5000,  0.1734, -0.0478, -0.0922])</b>
  </code>
  </pre>
</details>
    
<details>
  <summary><span><code>view(<i>*shape</i>) → Tensor</code></span><br/> <blockquote>Returns a tensor with the same data as the <b>self</b> tensor but of a different <b>shape</b>.<blockquote></summary>
  <pre>
  <code>
  >>> x = torch.randn(4, 4)
  >>> x.size()
  <b>torch.Size([4, 4])</b>
  >>> y = x.view(16)
  >>> y.size()
  <b>torch.Size([16])</b>
  >>> z = x.view(-1, 8)  # the size -1 is inferred from other dimensions<br>
  >>> z.size()
  <b>torch.Size([2, 8])</b>
  </code>
  </pre>
</details>

#### NN Functions
<details>
  <summary><code>loss.backward()</code><br/><blockquote>Computes <b>dloss/dx</b> for every parameter x which has <code>requires_grad=True</code>.<blockquote></summary>
  <hr>
    These are accumulated into <code>x.grad</code> for every parameter x.</br></br>
    <pre><code>x.grad += dloss/dx</code></pre>
    <code>optimizer.step</code> updates the value of x using the gradient <code>x.grad</code>. For example, the SGD optimizer performs:     </br></br>
    <pre><code>x += -lr * x.grad</code></pre>
    <code>optimizer.zero_grad()</code> clears <code>x.grad</code> for every parameter x in the optimizer. It’s important to call this before <code>loss.backward()</code>, otherwise you’ll accumulate the gradients from multiple passes.</br></br>
    If you have multiple losses (loss1, loss2) you can sum them and then call backwards once:</br></br>
    <pre>
    <code>loss3 = loss1 + loss2
    loss3.backward()</code></pre> 
    <hr>
</details>

## Mathematics
### Metrics

#### Manhatten distance 
- L<sub>1</sub> distance
- The distance between two points measured along axes at right angles. 
- In a plane with p<sub>1</sub> at (x<sub>1</sub>, y<sub>1</sub>) and p<sub>2</sub> at (x<sub>2</sub>, y<sub>2</sub>) it is <b>|x<sub>1</sub> - x<sub>2</sub>| + |y<sub>1</sub> - y<sub>2</sub>|</b>.

#### Euclidean distance
- L<sub>2</sub> distance
- The straight line distance between two points.
- In a plane with p<sub>1</sub> at (x<sub>1</sub>, y<sub>1</sub>) and p<sub>2</sub> at (x<sub>2</sub>, y<sub>2</sub>) it is <b>sqrt((x<sub>1</sub> - x<sub>2</sub>)<sup>2</sup> + (y<sub>1</sub> - y<sub>2</sub>)<sup>2</sup>)</b>.
  
<p align="center">
  <img src="https://camo.githubusercontent.com/3fd9528d3c336947a78bda29aa36d98218a237eb/687474703a2f2f6e6561726973742e61692f77702d636f6e74656e742f75706c6f6164732f323031372f31312f4c315f616e645f4c325f6c696e65732e706e67" width=500>
</p>

#### Sources
- https://xlinux.nist.gov/dads/HTML/manhattanDistance.html
- https://github.com/nearist/vsx-client/wiki/L1-versus-L2

### Sets
#### Permutations
- The re-ordering of elements in a set with a care for the order of the elements.
- For example, your locker unlocks with a specific permutation of 2, 3, 4 and 5 (e.g. 2453).

#### Combinations
- The re-ordering of elements in a set without a care for the order of the elements.
- For example, your locker would unlock with any permutation of 2, 3, 4 and 5 to truly be by combination.

#### Sources
- https://medium.com/i-math/combinations-permutations-fa7ac680f0ac
